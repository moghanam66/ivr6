import asyncio
import openai
import pandas as pd
import ast
import json
import time
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import redis
import azure.cognitiveservices.speech as speechsdk
import nest_asyncio
nest_asyncio.apply()
print("âœ… Nest async applied.")

# Azure Cognitive Search imports
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential
print("âœ… Azure Search modules imported.")

# Bot Framework dependencies
from botbuilder.core import ActivityHandler, TurnContext
from botbuilder.schema import ChannelAccount, Activity, ActivityTypes
print("âœ… Bot Framework modules imported.")

# RT client for GPTâ€‘4o realtime fallback (make sure the rtclient package is installed)
from rtclient import RTLowLevelClient, ResponseCreateMessage, ResponseCreateParams
print("âœ… RT client modules imported.")

# ------------------------------------------------------------------
# Configuration for Azure OpenAI, GPTâ€‘4o realtime, Azure Search, Redis, Speech
# ------------------------------------------------------------------
print("ğŸ”§ Setting up configuration...")

# Azure OpenAI configuration for embeddings
OPENAI_API_KEY = "8929107a6a6b4f37b293a0fa0584ffc3"
OPENAI_API_VERSION = "2023-03-15-preview"
OPENAI_ENDPOINT = "https://genral-openai.openai.azure.com/"
EMBEDDING_MODEL = "text-embedding-ada-002"  # Fast embedding model

# GPTâ€‘4o realtime 
RT_API_KEY = "9e76306d48fb4e6684e4094d217695ac"
RT_ENDPOINT = "https://general-openai02.openai.azure.com/"
RT_DEPLOYMENT = "gpt-4o-realtime-preview"
RT_API_VERSION = "2024-10-17"

# Azure Cognitive Search 
SEARCH_SERVICE_NAME = "mainsearch01"          
SEARCH_INDEX_NAME = "id"                      
SEARCH_API_KEY = "Y6dbb3ljV5z33htXQEMR8ICM8nAHxOpNLwEPwKwKB9AzSeBtGPav"

# Redis 
REDIS_HOST = "AiKr.redis.cache.windows.net"
REDIS_PORT = 6380
REDIS_PASSWORD = "OD8wyo8NiVxse6DDkEY19481Xr7ZhQAnfAzCaOZKR2U="

# Speech 
SPEECH_KEY = "3c358ec45fdc4e6daeecb7a30002a9df"
SPEECH_REGION = "westus2"

# Thresholds for determining whether a search result is â€œgood enough.â€
SEMANTIC_THRESHOLD = 3.4 
VECTOR_THRESHOLD = 0.91

print("âœ… Configuration constants set.")

# ------------------------------------------------------------------
# Initialize clients and load Q&A data
# ------------------------------------------------------------------
print("ğŸ”§ Initializing Azure OpenAI client for embeddings...")
client = openai.AzureOpenAI(
    api_key=OPENAI_API_KEY,
    api_version=OPENAI_API_VERSION,
    azure_endpoint=OPENAI_ENDPOINT
)
print("âœ… Azure OpenAI client initialized.")

print("ğŸ”§ Loading Q&A data from CSV...")
try:
    qa_data = pd.read_csv("qa_data.csv", encoding="windows-1256")
    print("âœ… CSV file loaded successfully!")
except Exception as e:
    print(f"âŒ Failed to load CSV file: {e}")
    exit()

print("ğŸ”§ Normalizing column names...")
qa_data.rename(columns=lambda x: x.strip().lower(), inplace=True)
print("âœ… Column names normalized.")

if "id" in qa_data.columns:
    qa_data["id"] = qa_data["id"].astype(str)
    print("âœ… 'id' column converted to string.")

print("ğŸ”§ Verifying required columns...")
if "question" not in qa_data.columns or "answer" not in qa_data.columns:
    print("âŒ CSV file must contain 'question' and 'answer' columns.")
    exit()
print("âœ… Required columns are present.")

# EMBEDDING GENERATION
def get_embedding(text):
    print(f"ğŸ”§ Generating embedding for text: {text}")
    try:
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text
        )
        embedding = response.data[0].embedding
        print(f"âœ… Embedding generated for text: {text}")
        return embedding
    except Exception as e:
        print(f"âŒ Failed to generate embedding for text '{text}': {e}")
        return None

# Generate embeddings if not already present
if "embedding" not in qa_data.columns or qa_data["embedding"].isnull().all():
    print("ğŸ”§ No embeddings found in CSV. Generating embeddings...")
    qa_data["embedding"] = qa_data["question"].apply(get_embedding)
    qa_data.to_csv("embedded_qa_data.csv", index=False)
    print("âœ… Embeddings generated and saved to 'embedded_qa_data.csv'.")
else:
    print("ğŸ”§ Embeddings column exists. Converting embeddings from CSV...")
    def convert_embedding(x):
        if isinstance(x, str):
            try:
                parsed = ast.literal_eval(x)
                print("âœ… Embedding parsed successfully.")
                return parsed
            except Exception as e:
                print("âŒ Failed to parse embedding:", e)
                return None
        return x
    qa_data["embedding"] = qa_data["embedding"].apply(convert_embedding)
    print("âœ… Using existing embeddings from CSV.")

print("ğŸ”§ Normalizing question text for matching...")
qa_data["question"] = qa_data["question"].str.strip().str.lower()
print("âœ… Question text normalized.")

print("ğŸ”§ Initializing Azure Cognitive Search client...")
search_client = SearchClient(
    endpoint=f"https://{SEARCH_SERVICE_NAME}.search.windows.net/",
    index_name=SEARCH_INDEX_NAME,
    credential=AzureKeyCredential(SEARCH_API_KEY)
)
print("âœ… Azure Cognitive Search client initialized.")

print("ğŸ”§ Converting Q&A data to documents for Azure Search...")
documents = qa_data.to_dict(orient="records")
print("âœ… Documents converted to dictionary.")

try:
    upload_result = search_client.upload_documents(documents=documents)
    print(f"âœ… Uploaded {len(documents)} documents to Azure Search.")
except Exception as e:
    print(f"âŒ Failed to upload documents: {e}")

print("ğŸ”§ Initializing Redis client...")
try:
    redis_client = redis.Redis(
        host=REDIS_HOST,
        port=REDIS_PORT,
        db=0,
        ssl=True,
        decode_responses=True,
        password=REDIS_PASSWORD
    )
    redis_client.ping()
    print("âœ… Successfully connected to Redis!")
except Exception as e:
    print(f"âŒ Failed to connect to Redis: {e}")

def check_redis_cache(query):
    print(f"ğŸ” Checking Redis cache for query: {query}")
    try:
        cached_answer = redis_client.get(query)
        if cached_answer:
            print(f"âœ… Using cached answer for query: {query}")
            return cached_answer
    except Exception as e:
        print(f"âŒ Redis error: {e}")
    print("â„¹ï¸ No cached answer found.")
    return None

def get_best_match(query):
    print(f"ğŸ” Getting best match for query: {query}")
    cached_response = check_redis_cache(query)
    if cached_response:
        return cached_response

    # --- Semantic Search ---
    print("ğŸ”§ Performing Semantic Search...")
    try:
        semantic_results = search_client.search(
            search_text=query,
            query_type="semantic",
            semantic_configuration_name="my-semantic-config-default",
            query_caption="extractive",
            select=["question", "answer"],
            top=3
        )
        print("âœ… Semantic search executed.")
        semantic_answer = next(semantic_results, None)
        if semantic_answer:
            reranker_score = semantic_answer.get("@search.reranker_score", None)
            if reranker_score is not None and reranker_score >= SEMANTIC_THRESHOLD:
                answer = semantic_answer["answer"]
                print("âœ… Found match using Semantic Search with score", reranker_score)
                redis_client.set(query, answer, ex=3600)
                return answer
            else:
                print("âŒ Semantic search result score below threshold:", reranker_score)
        else:
            print("âŒ No semantic search answers found.")
    except Exception as e:
        print(f"âŒ Semantic search error: {e}")

    # --- Vector Search ---
    print("ğŸ”§ Performing Vector Search...")
    try:
        query_embedding = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=query
        ).data[0].embedding
        print("âœ… Query embedding generated for vector search.")

        vector_query = VectorizedQuery(
            vector=query_embedding,
            k_nearest_neighbors=50,
            fields="embedding"
        )
        print("âœ… Constructed vector query.")

        vector_results = search_client.search(
            search_text=None,
            vector_queries=[vector_query],
            select=["question", "answer"],
            top=3
        )
        print("âœ… Vector search executed.")
        best_vector = next(vector_results, None)
        if best_vector:
            score = best_vector.get("@search.score", 0)
            if score >= VECTOR_THRESHOLD:
                answer = best_vector["answer"]
                print("âœ… Found match using Vector Search with score", score)
                redis_client.set(query, answer, ex=3600)
                return answer
            else:
                print("âŒ Vector search result score below threshold:", score)
        else:
            print("âŒ No vector search results found.")
    except Exception as e:
        print(f"âŒ Vector search error: {e}")

    print("âŒ No match found using Semantic or Vector Search")
    return None

# GPTâ€‘4o REALTIME FALLBACK (ASYNC)
async def get_realtime_response(user_query):
    print(f"ğŸ”§ Attempting GPTâ€‘4o realtime fallback for query: {user_query}")
    try:
        async with RTLowLevelClient(
            url=RT_ENDPOINT,
            azure_deployment=RT_DEPLOYMENT,
            key_credential=AzureKeyCredential(RT_API_KEY)
        ) as client_rt:
            instructions = "Ø£Ù†Øª Ø±Ø¬Ù„ Ø¹Ø±Ø¨ÙŠ. Ø§Ù†Ø§ Ù„Ø§ Ø§Ø±ÙŠØ¯ Ø§ÙŠØ¶Ø§ Ø§ÙŠ bold points  ÙÙŠ Ø§Ù„Ø§Ø¬Ø§Ø¨Ø©  Ùˆ Ù„Ø§ Ø§Ø±ÙŠØ¯ Ø¹Ù†ÙˆØ§ÙŠÙ† Ù…Ø±Ù‚Ù…Ø©" + user_query
            print("ğŸ”§ Sending realtime request with instructions.")
            await client_rt.send(
                ResponseCreateMessage(
                    response=ResponseCreateParams(
                        modalities={"text"},
                        instructions=instructions
                    )
                )
            )
            done = False
            response_text = ""
            while not done:
                message = await client_rt.recv()
                if message is None:
                    print("âŒ No message received from the real-time service.")
                    break
                print(f"ğŸ”§ Received message of type: {message.type}")
                if message.type == "response.done":
                    done = True
                    print("âœ… Realtime response completed.")
                elif message.type == "error":
                    done = True
                    print(f"âŒ Error in realtime response: {message.error}")
                elif message.type == "response.text.delta":
                    response_text += message.delta
                    print(f"ğŸ”§ Received delta: {message.delta}")
            return response_text
    except Exception as e:
        print(f"âŒ Failed to get real-time response: {e}")
        return "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙˆØ±ÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ù‹Ø§."

async def get_response(user_query):
    print(f"ğŸ” Processing query: {user_query}")
    response = get_best_match(user_query)
    if response:
        print(f"âœ… Found response in cache or search: {response}")
        return response

    print("ğŸ”§ No match found, falling back to GPTâ€‘4o realtime...")
    realtime_response = await get_realtime_response(user_query)
    if realtime_response:
        print(f"âœ… GPTâ€‘4o realtime response: {realtime_response}")
        try:
            redis_client.set(user_query, realtime_response, ex=3600)
            print("âœ… Response cached in Redis.")
        except Exception as e:
            print(f"âŒ Failed to cache response in Redis: {e}")
        return realtime_response
    else:
        print("âŒ Realtime response empty.")
        return "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ù‹Ø§."

print("ğŸ”§ Setting up Speech configuration...")
speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
speech_config.speech_recognition_language = "ar-EG"
speech_config.speech_synthesis_voice_name = "ar-EG-ShakirNeural"
print("âœ… Speech configuration set.")

def recognize_speech():
    print("ğŸ”Š Starting speech recognition...")
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    print("ğŸ”Š Listening... (Speak in Egyptian Arabic)")
    result = recognizer.recognize_once_async().get()
    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        print(f"âœ… Speech recognized: {result.text}")
        return result.text
    else:
        print(f"âŒ Speech not recognized: {result.reason}")
        return ""

def speak_response(text):
    print(f"ğŸ”Š Speaking response: {text}")
    audio_output = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)
    result = synthesizer.speak_text_async(text).get()
    if result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        print("âŒ Speech synthesis canceled:")
        print("  Reason: {}".format(cancellation.reason))
        print("  Error Details: {}".format(cancellation.error_details))
    else:
        print("âœ… Speech synthesis completed.")

def clean_text(text):
    cleaned = text.strip(" .ØŒ!Ø›ØŸ").lower()
    print(f"ğŸ”§ Cleaning text. Before: '{text}' After: '{cleaned}'")
    return cleaned

def detect_critical_issue(text):
    print(f"ğŸ”§ Detecting critical issue in text: {text}")
    trigger_sentences = [
        "ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ø®ØªØ±Ø§Ù‚ Ø£Ù…Ù†ÙŠ ÙƒØ¨ÙŠØ±.",
        "ØªÙ…ÙƒÙ† Ù‚Ø±Ø§ØµÙ†Ø© Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø§Ø³Ø©.",
        "Ù‡Ù†Ø§Ùƒ Ù‡Ø¬ÙˆÙ… Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ù†Ø§.",
        "ØªÙ… ØªØ³Ø±ÙŠØ¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª.",
        "Ø±ØµØ¯Ù†Ø§ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØµÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¶Ø¯ Ù…ÙˆØ¸ÙÙŠÙ†Ø§.",
        "ØªÙ… Ø§Ø³ØªØºÙ„Ø§Ù„ Ø«ØºØ±Ø© Ø£Ù…Ù†ÙŠØ© ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©.",
        "Ù‡Ù†Ø§Ùƒ Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ ØºÙŠØ± Ù…ØµØ±Ø­ Ø¨Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø³Ø±ÙŠØ©."
    ]
    trigger_embeddings = np.array([get_embedding(sent) for sent in trigger_sentences])
    text_embedding = np.array(get_embedding(text)).reshape(1, -1)
    similarities = cosine_similarity(text_embedding, trigger_embeddings)
    max_similarity = np.max(similarities)
    print(f"âœ… Maximum similarity with trigger sentences: {max_similarity}")
    if max_similarity > 0.9:
        print("âš ï¸ Critical issue detected. This issue should be passed to a human.")
        return True
    print("âœ… No critical issue detected.")
    return False

async def voice_chat(turn_context: TurnContext, user_query: str):
    print(f"ğŸ”Š Voice chat started with query: {user_query}")
    if not user_query:
        print("â„¹ï¸ Empty user query received.")
        return "ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙˆØ§Ù…Ø±Ùƒ"
    if clean_text(user_query) in ["Ø¥Ù†Ù‡Ø§Ø¡", "Ø®Ø±ÙˆØ¬"]:
        print("ğŸ‘‹ Goodbye command received.")
        return "Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©"
    if detect_critical_issue(user_query):
        print("âš ï¸ Critical issue detected in voice chat.")
        return "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¯Ø®Ù„ Ø¨Ø´Ø±ÙŠ. Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ù„Ø¯Ø¹Ù…Ùƒ."
    response = await get_response(user_query)
    print(f"âœ… Voice chat response: {response}")
    activity: Activity = turn_context.activity
    bot_id = activity.recipient.id
    return Activity(
        type=ActivityTypes.message,
        from_property=ChannelAccount(id="8:bot:ms-poc-contact-center-voice-bot"),  # Bot as the sender
        text=response
    )
    # return response

class MyBot(ActivityHandler):
    async def on_message_activity(self, turn_context: TurnContext):
        user_query = turn_context.activity.text
        print(f"ğŸ“© Received message: {user_query}")
        response_text = await voice_chat(turn_context, user_query)
        print("ğŸ“¤ Sending response back to user.")
        print(f"response: {response_text}")
        await turn_context.send_activity(response_text)

    async def on_members_added_activity(self, members_added: ChannelAccount, turn_context: TurnContext):
        print("ğŸ‘¥ New members added to the conversation.")
        for member in members_added:
            if member.id != turn_context.activity.recipient.id:
                welcome_activity = Activity(               
                    type=ActivityTypes.message,
                    from_property=ChannelAccount(
                        id="8:bot:ms-poc-contact-center-voice-bot"
                        # You can include the bot's name if available.
                    ),
                    text="Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
                )
                print(f"welcome_activity: {welcome_activity}")
                print("ğŸ“© Sending welcome message.")
                await turn_context.send_activity(welcome_activity)

print("âœ… All modules and configurations are set. Bot is ready to run!")
